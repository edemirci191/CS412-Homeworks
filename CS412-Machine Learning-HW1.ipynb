{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1-demirci-emre.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voHKcAfRfdNY"
      },
      "source": [
        "# CS412 - Machine Learning - 2020\n",
        "## Homework 1\n",
        "100 pts\n",
        "\n",
        "\n",
        "## Goal\n",
        "\n",
        "The goal of this homework is three-fold:\n",
        "\n",
        "*   Introduction to the machine learning experimental set up \n",
        "*   Gain experience with Decision tree approache\n",
        "*   Gain experience with the Scikit library\n",
        "\n",
        "## Dataset\n",
        "**MNIST** is a collection of 28x28 grayscale images of digits (0-9); hence each pixel is a gray-level from 0-255. \n",
        "\n",
        "**Download the data from Keras. You must use a 20% of the training data for validation** (no need for cross-validation as you have plenty of data) and **use the official test data (10,000 samples) only for testing.**\n",
        "\n",
        "## Task \n",
        "Build a decision tree classifier with the scikit library function calls to classify digits in the MNIST dataset.\n",
        "\n",
        "## Software: You may find the necessary function references here:\n",
        "http://scikit-learn.org/stable/supervised_learning.html\n",
        "\n",
        "## Submission: \n",
        "Fill this notebook and submit this document with a link to #your Colab notebook \n",
        "(make sure to include the link obtained from the #share link on top right)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YOYiWvHbNDW"
      },
      "source": [
        "##1) Initialize\n",
        "\n",
        "*   First make a copy of the notebook given to you as a starter.\n",
        "\n",
        "*   Make sure you choose Connect form upper right.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM-wwHR8qL0M"
      },
      "source": [
        "## 2) Load training dataset\n",
        "\n",
        "*  Read from Keras library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz3iMpjVfa5I"
      },
      "source": [
        "# Load the Pandas libraries with alias 'pd' \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Read data \n",
        "from keras.datasets import mnist  \n",
        "(trainData_2D, trainLabels), (testData_2D, testLabels) = mnist.load_data() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NdW2ItjHLxJ"
      },
      "source": [
        "##3) Understanding the dataset\n",
        "\n",
        "There are alot of functions that can be used to know more about this dataset\n",
        "\n",
        "- What is the shape of the training set (num of samples X number of attributes) ***[shape function can be used]***\n",
        "\n",
        "- Display attribute names ***[columns function can be used]***\n",
        "\n",
        "- Display the first 5 rows from training dataset ***[head or sample functions can be used]***\n",
        "\n",
        "Note: Understanding the features, possibly removing some features etc. is an important part in building an ML system, but for this homework this is not really necessary as  the features are homogeneous (pixels) and all necessary.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA_AjGQasjvS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "045f3156-f2e8-4fc8-cc2b-f22f7a58ec71"
      },
      "source": [
        "# print shape\n",
        "print('Data Dimensionality: ')\n",
        "print(trainData_2D.shape)\n",
        "\n",
        "# print first 5 rows in your dataset\n",
        "print('Head of Data: ')\n",
        "\n",
        "#We need to reshape first // this is for training data\n",
        "train_sz = trainData_2D.shape\n",
        "trainData = np.reshape(trainData_2D,(train_sz[0],train_sz[1]*train_sz[2])).astype('float32')\n",
        "#and this is for test data\n",
        "test_sz = testData_2D.shape\n",
        "testData = np.reshape(testData_2D,(test_sz[0],test_sz[1]*test_sz[2])).astype('float32')\n",
        "\n",
        "# Now let us normalize it even if it is not necessary in this case to make computations faster\n",
        "from sklearn.preprocessing import normalize\n",
        "trainData = normalize(trainData)\n",
        "testData = normalize(testData)\n",
        "\n",
        "trainData = pd.DataFrame(trainData)#convert numpy to pandas\n",
        "testData = pd.DataFrame(testData)\n",
        "\n",
        "trainData.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Dimensionality: \n",
            "(60000, 28, 28)\n",
            "Head of Data: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.065585</td>\n",
              "      <td>0.112431</td>\n",
              "      <td>0.018739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    6    ...  777  778  779  780  781  782  783\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vop4rwZVxh9Z"
      },
      "source": [
        "##4) Shuffle and Split TRAINING data as train (also called development) (80%) and validation (20%) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEhk8R24xhdY"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "# i guess train_test_split automatically shuffles\n",
        "# shuffle(trainData,random_state=20)\n",
        "\n",
        "# Split 80-20\n",
        "from sklearn.model_selection import train_test_split\n",
        "(train_x, val_x, train_y, val_y) = train_test_split(trainData,trainLabels, test_size = 0.2, random_state = 12) # I splitted it %20 and %80\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RClqbyHbnt91"
      },
      "source": [
        "**Accuracy scores becomes higher when i dont use shuffle(trainData,random_state = 20) in part 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR1oMsPu0AV_"
      },
      "source": [
        "##5) Train a decision tree classifier on development/train data and do model selection using the validation data\n",
        "\n",
        "* Train 3 decision tree classifiers with different values of \"min_samples_split\" which is the minimum number of samples required to split an internal node:  min_samples_split = [default = 2, 5, 10]. \n",
        "* Test the 3 models on validation set and choose the best one.\n",
        "* Plot the train and validation set errors for those 3 settings - on one plot. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv6oac-T3Wy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3f113d62-0c1c-4a37-8287-317e7bb2fa0e"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Train decision tree classifiers\n",
        "min_samples_split = [2,5,10]\n",
        "\n",
        "for samples in min_samples_split:\n",
        "  clf_min_samples_split = DecisionTreeClassifier(min_samples_split = samples, random_state = 0)\n",
        "  clf_min_samples_split.fit(train_x,train_y)\n",
        "# Evaluate on validation set\n",
        "  y_pred = clf_min_samples_split.predict(val_x)\n",
        "  val_acc = accuracy_score(val_y, y_pred)\n",
        "  print(\"Accuracy Score for validation\",val_acc)\n",
        "  train_y_pred = clf_min_samples_split.predict(train_x)\n",
        "  train_acc = accuracy_score(train_y, train_y_pred)\n",
        "  print(\"Accuracy Score for train\",train_acc)\n",
        "  # Plot errors\n",
        "x_axis = ['model1', 'model2', 'model3']\n",
        "plt.scatter(x_axis, val_acc)\n",
        "plt.scatter(x_axis, train_acc)\n",
        "plt.plot(x_axis, val_acc, label = \"Validation acc\")\n",
        "plt.plot(x_axis, train_acc, label = \"Train acc\")\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score for validation 0.8720833333333333\n",
            "Accuracy Score for train 1.0\n",
            "Accuracy Score for validation 0.871\n",
            "Accuracy Score for train 0.9826041666666666\n",
            "Accuracy Score for validation 0.8695833333333334\n",
            "Accuracy Score for train 0.9663541666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA6b_7pYuOLN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "3000a3ae-0377-4be9-cf55-4edfaef471ad"
      },
      "source": [
        "x_axis = ['model1', 'model2', 'model3']\n",
        "val_acc = [0.8720833333333333 ,0.871, 0.8695833333333334] # because i found the results above i just write it like this\n",
        "train_acc = [1.0, 0.9826041666666666, 0.9663541666666666] # because i found the results above i just write it like this\n",
        "plt.scatter(x_axis, val_acc)\n",
        "plt.scatter(x_axis, train_acc)\n",
        "plt.plot(x_axis, val_acc, label = \"Validation acc\")\n",
        "plt.plot(x_axis, train_acc, label = \"Train acc\")\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx-PvyFdnde2"
      },
      "source": [
        "**Accuracy scores becomes lower if i use shuffle(trainData,random_state = 20) in part 4... so i did not because i think train_test_split automatically shuffles**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boqe46St1--f"
      },
      "source": [
        "## 7) Test your CHOSEN classifier on Test set\n",
        "\n",
        "- Load test data\n",
        "- Apply same pre-processing as training data (probably none)\n",
        "- Predict the labels of testing data **using the best chosen SINGLE model out of the models that you have tried from step 6 (you have selected your model according to your validation results)** and report the accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPLke8jyFGng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea37921d-aaf0-46e3-96aa-8ba27447d7b2"
      },
      "source": [
        "# Load test data\n",
        "clf = DecisionTreeClassifier(min_samples_split= 2,random_state= 0)\n",
        "clf.fit(trainData,trainLabels)\n",
        "\n",
        "\n",
        "\n",
        "# test prediction using a decision tree with all default parameters and ..... min-split value \n",
        "y_pred = clf.predict(testData)\n",
        "\n",
        "\n",
        "\n",
        "# Report your accuracy\n",
        "print(\"Accuracy Score\", accuracy_score(testLabels,y_pred))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.8813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG3473I9dGE8"
      },
      "source": [
        "##8) Notebook & Report \n",
        "\n",
        "**Notebook: We may just look at your notebook results; so make sure each cell is run and  outputs are there.**\n",
        "\n",
        "**Report: Write an at most 1/2 page summary of your approach to this problem at the end of your notebook**; this should be like an abstract of a paper or the executive summary (you aim for clarity and passing on information, not going to details about known facts such as what dec. trees are or what MNIST is, assuming they are known to people in your research area). \n",
        "\n",
        "**Must include statements such as:**\n",
        "\n",
        " ( Include the problem definition: 1-2 lines )\n",
        " \n",
        "  (Talk about train/val/test sets, size and how split. )\n",
        " \n",
        "  (Talk about any preprocessing you do.)\n",
        "  \n",
        " ( Give the validation accuracies for different approaches, parameters **in a table** and state which one you selected)\n",
        " \n",
        " ( State  what your test results are with the chosen method, parameters: e.g. \"We have obtained the best results with the ….. classifier      (parameters=....) , giving classification accuracy of …% on test data….\"\"\n",
        "\n",
        "  (Comment on the speed of the algorithms and anything else that you deem important/interesting (e.g. confusion matrix)).\n",
        "\n",
        "*You will get full points from here as long as you have a good (enough) summary of your work, regardless of your best performance or what you have decided to talk about in the last few lines.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG9Vq-RWwSYE"
      },
      "source": [
        "Problem was to classify grayscale images using decision trees.\n",
        "There were 784 rows in train dataset when we reduced the dimension from 2d to 1d.\n",
        "\n",
        "What i did was, i created decision trees with different parameters. I downloaded dataset \"mnist\". I did some pre processing, like i reduced the dimension of data from 2d to 1 d and then i normalized the dataset so computations became faster and more accurate i believe. After that i splitted the data into two folds for validation and training. Using these datasets i trained decision trees with it. Then i calculated accuracy scores ( 1- error) and then i plotted it. Finally i created another model using the best parameters i found. In part 4, instrucions asked me to shuffle. I tried a function called shuffle but when i use that accuracy scores become abundantly lower like %10 so i searched a little and then i read couple of things about train_test_split. I believe that did the shuffling already. \n",
        "\n",
        "Accuracy Score for validation 0.8720833333333333\n",
        "Accuracy Score for train 1.0\n",
        "Accuracy Score for validation 0.871\n",
        "Accuracy Score for train 0.9826041666666666\n",
        "Accuracy Score for validation 0.8695833333333334\n",
        "Accuracy Score for train 0.9663541666666666\n",
        "\n",
        "Accuracy values can be seen from above i choose the first model because it gave 0.87 accuracy in validation data. I have obtained the best result (0.87) with min_samples_split with 2 parameters instead of 5 or 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOVrzIhFm5L0"
      },
      "source": [
        "##9) Submission\n",
        "\n",
        "Please submit your **\"share link\" INLINE in Sucourse submissions**. That is we should be able to click on the link and go there and run (and possibly also modify) your code. \n",
        "\n",
        "For us to be able to modify, in case of errors etc, **you should get your \"share link\" as **share with anyone in edit mode** \n",
        "\n",
        " **Also submit your notebook as pdf as attachment**, choose print and save as PDF, save with hw1-lastname-firstname.pdf to facilitate grading. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGUOrh3Wdrj8"
      },
      "source": [
        "## Questions? \n",
        "\n",
        "You can and should ask all your Google Colab related questions under Forums  and feel free to answer/share your answer regarding Colab. \n",
        "\n",
        "You can also ask/answer about which functions to use and what libraries... \n",
        "\n",
        "However you should **not ask** about the core parts, that is what is validation/test, which one shd. have higher performance, what are your scores etc.\n"
      ]
    }
  ]
}